---
layout: page
title: NSNLI
subtitle: Is Neuro-Symbolic SOTA still a myth for Natural Language Inference?
---

<h2>Speakers</h2>
<div class="row">
    <div class="col-sm-3 text-center" id="smuresan" style="height: 200px">
        <img src="/assets/img/smarandam.jpg" alt="Smaranda Muresan" class="img-circle" style="height:150px;width:150px;margin:5px;border-radius: 50%"/>
        <br/>
        <a href="http://www.cs.columbia.edu/~smara/">Smaranda Muresan</a>
        <br/>
        Combia University
    </div>
    <div class="col">
        <div class="col-md-12" id="smuresan">
        <b> Talk Title & Abstract</b>: TBA
        <p><b> Speaker Bio</b>: (To be Updated) Prof. Smaranda Muresan is a Research Scientist at the Data Science Institute (DSI) and the Department of Computer Science at Columbia University. She is also an Adjunct Associate Professor in the Department of Computer Science. Her research is focused on computational models for understanding language in context, such as social context, visual context or multilingual context, with application to computational social science, education and public health. Specific areas of interest are argument mining and persuasion, figurative language understanding and generation, multilingial language processing for low resource languages, NLP for social good. </p>
        </div>
    </div>
</div>
<div class="row">
<br/>
    <div class="col-sm-3 text-center" id="jberant" style="height: 200px">
        <img src="/assets/img/jberant.png" alt="Jonathan Berant" class="img-circle" style="height:150px;width:150px;margin:5px;border-radius: 50%"/>
        <br/>
        <a href="http://www.cs.tau.ac.il/~joberant/">Jonathan Berant</a>
        <br/>
        Tel Aviv University / Allen Inst. of AI
    </div>
    <div class="col">
        <div class="col-md-12" id="jberant">
        <b> Talk Title </b>: Neuro-symbolic models for understanding complex questions <br>
        <button type="button" class="btn btn-info" data-toggle="collapse" data-target="#demo1" style="background-color:#fff;color:#1e17b8;border:none;padding-left: 0px;font-size:large"><b> Abstract >></b></button><br>
        <div id="demo1" class="collapse">
            Questions that require integrating information over multiple pieces of information are important both from an applicative point-of-view, as such questions naturally arise in real life, and from a scientific point-of-view, as they allow us to test the reasoning abilities of our models. In this talk, I will describe symbolic representations for complex questions and will demonstrate their utility for multiple purposes. First, for improving compositional generalization, that is, the ability of question answering models to handle new compositions that did not occur at training time. Second, for achieving faithfulness, that is, for validating that the computation performed by a neural model indeed corresponds to our human intuitions. Last, for evaluation and robustness, that is, to automatically generate synthetic examples that evaluate and can improve model robustness.
        </div>
        <!-- <button type="button" class="btn btn-info" data-toggle="collapse in" data-target="#bio1" style="background-color:#fff;color:#1e17b8;;border:none;padding-left: 0px;font-size:large"><b> Speaker Bio >></b></button> -->
        <!-- <div id="bio1" class="collapse"> -->
        <p><b> Speaker Bio</b>: Jonathan Berant is an associate professor at the School of Computer Science at Tel Aviv University and a research scientist at The Allen Institute for AI. Jonathan earned a Ph.D. in Computer Science at Tel-Aviv University, under the supervision of Prof. Ido Dagan. Jonathan was a post-doctoral fellow at Stanford University, working with Prof. Christopher Manning and Prof. Percy Liang, and subsequently a post-doctoral fellow at Google Research, Mountain View. Jonathan Received several awards and fellowships including The Rothschild fellowship, The ACL 2011 best student paper award, EMNLP 2014 best paper award, and NAACL 2019 best resource paper award, as well as several honorable mentions. Jonathan is currently an ERC grantee.</p>
        <!-- </div> -->
        </div>
    </div>
</div>
<div class="row">
<br/>
    <div class="col-sm-3 text-center" id="abosselut" style="height: 200px">
        <img src="/assets/img/abosselut.jpg" alt="Antoine Bosselut" class="img-circle" style="height:150px;width:150px;margin:5px;border-radius: 50%"/>
        <br/>
        <a href="https://atcbosselut.github.io/">Antoine Bosselut</a>
        <br/>
        Stanford University
    </div>
    <div class="col">
        <div class="col-md-12" id="abosselut">
        <b> Talk Title </b>: Symbolic Scaffolds for Neural Commonsense Representation and Reasoning <br>
        <button type="button" class="btn btn-info" data-toggle="collapse" data-target="#demo2" style="background-color:#fff;color:#1e17b8;border:none;padding-left: 0px;font-size:large"><b> Abstract >></b></button>
        <div id="demo2" class="collapse">
            Situations described using natural language are richer than what humans explicitly communicate. For example, the sentence "She pumped her fist" connotes many potential auspicious causes. For machines to understand natural language, they must be able to make commonsense inferences about explicitly stated information. However, current NLP systems lack the ability to ground the situations they encounter to relevant world knowledge. Moreover, they struggle to reason over available facts to robustly generalize to future unseen events. In this talk, I will describe efforts at measuring the degree of commonsense knowledge already encoded by large-scale language models, and discuss how this understanding motivates the design of commonsense reasoning interfaces for NLP systems
        </div>
        <p><b> Speaker Bio</b>: Antoine Bosselut is a Postdoctoral Scholar at Stanford University and a Young Investigator at the Allen Institute for AI (AI2). He will join the École Polytechnique Fédéral de Lausanne (EPFL) as an Assistant Professor in 2021. He received his PhD at the University of Washington in 2020. He was recently named as one of the Forbes 30 under 30 list for Science and Healthcare. His research is on building knowledge-aware NLP systems, specializing in commonsense representation and reasoning. </p>
        </div>
    </div>
</div>

Talk Title and Abstract to be updated!

<h2>Program Committee</h2>

Arun Iyer, Microsoft Research India <br>
Aws Albarghouthi, University of Wisconsin-Madison <br>
Chandra Bhagavatula, AI2 <br>
Charles Sutton, Google Brain <br>
Kartik Talamadapula, IBM Research <br>
Leon Weber, Humboldt University of Berlin <br>
Matko Bošnjak, UCL <br>
Robin Manhaeve, KU Leuven <br>
Thomas Demeester, Ghent University <br>

<!-- 
Luc de Raedt, KU Leuven <br>
Vivek Srikumar, University of Utah <br>
Kuldeep Meel, National University of Singapore <br>
Mausam, IIT Delhi <br>
Forough Arabshahi, Facebook <br>
Chitta Baral, Arizona State University <br>
Giuseppe Marra, KU Leuven <br>
Thomas Winters, KU Leuven <br>
Kevin Ellis, Cornell University <br>
Rishabh Singh, Google <br>
Aws Albarghouthi, Wisconsin  -->